---
title: Langchain ä¸ªäººä½¿ç”¨æŒ‡å—
article: true
date: 2023-06-18 15:54
---

```tasks

(path includes å¼€æºé¡¹ç›®)
explain
```

ä¸»è¦æ˜¯æ ¹æ®å®˜æ–¹æ–‡æ¡£æ¥çš„

## modules

### llms

### Prompts

#### output_parsers

output_parsers æ˜¯ä¸€ä¸ª ABC, ä¸»è¦çš„æ–¹æ³•æœ‰è¿™äº›:  
`<class:output_parsers>.get_format_instructions()`  
ä¼šè¿”å›æ‰€å®ç”¨çš„ Output parser çš„ Instructions.

`<class:output_parsers>.dict()` ä¼šè¿”å›ä¸€ä¸ªç±»ä¼¼å¦‚ä¸‹çš„è¯­å¥

```
{'format': '%Y-%m-%dT%H:%M:%S.%fZ', '_type': 'datetime'}
```

`<class:output_parsers>.parse(responseã€€:str)` å¯¹è¿”å›çš„æ–‡å­—æŒ‰ç…§æ‰€é€‰æ‹©çš„ parse è¿›è¡Œä¿¡æ¯æå–.

##### CommaSeparatedListOutputParser()

```python
output_parser = CommaSeparatedListOutputParser()
format_instructions =output_parser.get_format_instructions()

prompt = PromptTemplate(
template="List five {subject}.\n{format_instructions}",
input_variables=["subject"],
partial_variables={"format_instructions":format_instructions}
)
```

å°±æ˜¯åœ¨ prompt ååŠ äº†ä¸€å¥å¦‚ä¸‹çš„è¯:

```text
Your response should be a list of comma separated values, eg: `foo, bar, baz`
```

ç„¶åå¯¹äºè¿”å›çš„è¯­å¥ä½¿ç”¨ `output_parser.parse(output)`,å°±å¯ä»¥æŠ“åˆ°ä¸€ä¸ªåˆ—è¡¨.

å¦‚æœä½¿ç”¨çš„æ˜¯ ChatModel çš„è¯,éœ€è¦è¿›è¡Œå¦‚ä¸‹æ“ä½œ

```python
chatTemp:str =  prompt.format(subject="ice cream flavors")
AIMessage = AIMessagePromptTemplate.from_template(chatTemp).format_messages()
model = ChatOpenAI(temperature=0)
output = model(AIMessage)
output_parser.parse(output.content) #å³å¯ä»¥è·å¾—åˆ—è¡¨
```

##### DatetimeOutputParser()

ä½¿ç”¨æ–¹æ³•åŒä¸Š,å…·ä½“æ¥è¯´å°±æ˜¯åœ¨åŸæœ‰çš„ prompt ä¸ŠåŠ äº†ä¸€å¥å¦‚ä¸‹çš„è¯:

```
Write a datetime string that matches the following pattern: "%Y-%m-%dT%H:%M:%S.%fZ". Examples: 1290-12-08T11:55:33.743538Z, 1764-07-13T00:01:08.462257Z, 1095-01-18T11:35:53.457565Z
```

ä½¿ç”¨åŒæ ·çš„ parse è·å–æ—¶é—´

```python
output_parser = DatetimeOutputParser()
output_parser.parse(output)
#output: datetime.datetime(2009, 1, 3, 18, 15, 5)
```

ä½¿ç”¨ `<class:datetime.datetime>.strftime("%Y-%m-%d %H:%M:%S")` å°†æ—¶é—´å˜æˆè‡ªå·±æƒ³è¦çš„æ—¶é—´

```python
formatted_date = time.strftime("%Y-%m-%d %H:%M:%S")
print(f"Answer: {formatted_date}")
#output: Answer: 2009-01-03 18:15:05
```

##### EnumOutputParser()

å¯ä»¥è®¾ç½®ä¸€ä¸ªå±æ€§

```python
from langchain.output_parsers.enum import EnumOutputParser
from enum import Enum

class Colors(Enum):
RED = "red"
GREEN = "green"
BLUE = "blue"

parser = EnumOutputParser(enum=Colors)
parser.parse("red") #<Colors.RED: 'red'>
parser.parse(" green") #<Colors.GREEN: 'green'>
parser.parse(" blue\n") #<Colors.BLUE: 'blue'>
parser.parse("yellow") #æŠ¥é”™
```

æ„Ÿè§‰æ²¡ä»€ä¹ˆç”¨å•Š...

##### PydanticOutputParser()

è¿™æ˜¯ PydanticOutputParser çš„ä¸€äº›å†…ç½®å‡½æ•°

```python
    def get_format_instructions(self) -> str:
        schema = self.pydantic_object.schema()

        # Remove extraneous fields.
        reduced_schema = schema
        if "title" in reduced_schema:
            del reduced_schema["title"]
        if "type" in reduced_schema:
            del reduced_schema["type"]
        # Ensure json in context is well-formed with double quotes.
        schema_str = json.dumps(reduced_schema)

        return PYDANTIC_FORMAT_INSTRUCTIONS.format(schema=schema_str)
```

```python
  def parse(self, text: str) -> T:
        try:
            # Greedy search for 1st json candidate.
            match = re.search(
                r"\{.*\}", text.strip(), re.MULTILINE | re.IGNORECASE | re.DOTALL
            )
            json_str = ""
            if match:
                json_str = match.group()
            json_object = json.loads(json_str, strict=False)
            return self.pydantic_object.parse_obj(json_object)

        except (json.JSONDecodeError, ValidationError) as e:
            name = self.pydantic_object.__name__
            msg = f"Failed to parse {name} from completion {text}. Got: {e}"
            raise OutputParserException(msg)
```

æ„Ÿè§‰è¿™ä¸ªåº”è¯¥æ˜¯æœ€æœ‰ç”¨çš„äº†!

ä¸€ä¸ª eg

```python
# Here's another example, but with a compound typed field.
class Actor(BaseModel):
    name: str = Field(description="name of an actor")
    film_names: List[str] = Field(description="list of names of films they starred in")

actor_query = "Generate the filmography for a random actor."

parser = PydanticOutputParser(pydantic_object=Actor)

prompt = PromptTemplate(
    template="Answer the user query.\n{format_instructions}\n{query}\n",
    input_variables=["query"],
    partial_variables={"format_instructions": parser.get_format_instructions()}
)

_input = prompt.format_prompt(query=actor_query)

output = model(_input.to_string())

parser.parse(output)
```

```text
Actor(name='Tom Hanks', film_names=['Forrest Gump', 'Saving Private Ryan', 'The Green Mile', 'Cast Away', 'Toy Story'])
```

##### OutputFixingParser()

æŒºæŠ½è±¡çš„,åŒ…è£…ä¸€ä¸ª parser å¹¶ä¿®æ”¹å®ƒçš„é”™è¯¯.  
è§‰å¾—æŒºå¥½ç©çš„,ç›´æ¥æ”¾æºç äº†

```python
class OutputFixingParser(BaseOutputParser[T]):
    """Wraps a parser and tries to fix parsing errors."""

    parser: BaseOutputParser[T]
    retry_chain: LLMChain

    @classmethod
    def from_llm(
        cls,
        llm: BaseLanguageModel,
        parser: BaseOutputParser[T],
        prompt: BasePromptTemplate = NAIVE_FIX_PROMPT,
    ) -> OutputFixingParser[T]:
        chain = LLMChain(llm=llm, prompt=prompt)
        return cls(parser=parser, retry_chain=chain)

    def parse(self, completion: str) -> T:
        try:
            parsed_completion = self.parser.parse(completion)
        except OutputParserException as e:
            new_completion = self.retry_chain.run(
                instructions=self.parser.get_format_instructions(),
                completion=completion,
                error=repr(e),
            )
            parsed_completion = self.parser.parse(new_completion)

        return parsed_completion

    def get_format_instructions(self) -> str:
        return self.parser.get_format_instructions()
```

å°±æ˜¯å† call ä¸€æ¬¡ ai,è®© ai å¸®æˆ‘ä»¬ fix

```
NAIVE_FIX = """Instructions:
--------------
{instructions}
--------------
Completion:
--------------
{completion}
--------------

Above, the Completion did not satisfy the constraints given in the Instructions.
Error:
--------------
{error}
--------------

Please try again. Please only respond with an answer that satisfies the constraints laid out in the Instructions:"""

```

æ„Ÿè§‰è¿˜è›®æœ‰æ„æ€çš„,å°±æ˜¯ ai æ¯æ¬¡éƒ½ä¼šè¿”å›æ­£ç¡®çš„å—? ä¿æŒæ€€ç–‘.

#save è¿™ä¸ª OutputFixingParser çš„è°ƒç”¨æ–¹æ³•è¿˜è›®æœ‰æ„æ€çš„æ„Ÿè§‰ä»¥åå¯ä»¥çœ‹æºç æ¥å­¦ä¹ .

##### RetryOutputParser()

ä¸æƒ³æ€»ç»“äº† æœ‰æ—¶é—´åœ¨åšå§

- [x] æ€»ç»“è¿™ä¸€ç«  ğŸ›« 2023-06-19 ğŸ“… 2023-06-25 âœ… 2023-11-14

##### StructuredOutputParser()

å¼ƒç”¨

### Memory

#### ChatMessageHistory()

ä¸²èµ·æ¥äº†

```python
from langchain.memory import ChatMessageHistory
history = ChatMessageHistory()
history.add_user_message("hi!")
history.add_ai_message("whats up?")

print(history.messages)
# [HumanMessage(content='hi!', additional_kwargs={}, example=False), AIMessage(content='whats up?', additional_kwargs={}, example=False)]
```

#### ConversationBufferMemory()

å¦ä¸€ç§ Memory. æ„Ÿè§‰ä¸å¦‚ ChatMessageHistory.

```python
from langchain.memory import ConversationBufferMemory
memory = ConversationBufferMemory()
memory.chat_memory.add_user_message("hi!")
memory.chat_memory.add_ai_message("whats up?")
memory.load_memory_variables({})
# {'history': 'Human: hi!\nAI: whats up?'}
memory = ConversationBufferMemory(return_messages=True)
memory.chat_memory.add_user_message("hi!")
memory.chat_memory.add_ai_message("whats up?")
memory.load_memory_variables({})
# {'history': [HumanMessage(content='hi!', additional_kwargs={}, example=False), AIMessage(content='whats up?', additional_kwargs={}, example=False)]}
```

åªæœ‰ history ä¸€ä¸ªå±æ€§?,æˆ‘ä¸ä¿¡. å¥½å§, è¿˜çœŸæ˜¯....

å¯ä»¥é€šè¿‡ memory.chat_memory.add_message(\*history.messages)  
æŠŠ chatmessge åŠ å…¥åˆ° buffer é‡Œ

#### åœ¨ [[#Chains]] ä¸­ä½¿ç”¨ Memory

[[#ConversationChain()]]

##### adding_memory

... éš¾å´©

```python
template = """You are a chatbot having a conversation with a human.

{chat_history}
Human: {human_input}
Chatbot:"""

prompt = PromptTemplate(
    input_variables=["chat_history", "human_input"],
    template=template
)
memory = ConversationBufferMemory(memory_key="chat_history")
```

é€šè¿‡ memory ç±»å‹å:  
ç±»å‹å: <class 'langchain.memory.buffer.ConversationBufferMemory'>  
å¯é€‰å‚æ•°:\['lc_kwargs', 'chat_memory', 'output_key', 'input_key', 'return_messages', 'human_prefix', 'ai_prefix', 'memory_key']  
å¿…é¡»å‚æ•°:\[]

```python
llm_chain = LLMChain(
    llm=OpenAI(),
    prompt=prompt,
    verbose=True,
    memory=memory,
)
llm_chain.predict(human_input="Hi there my friend")
# " Hi there! It's great to meet you! How are you doing today?"
llm_chain.predict(human_input="Not too bad - how are you?")
# " I'm doing great, thank you for asking!"
```

##### adding_memory_with_doc_and_memory

```ad-info
å¯èƒ½ä»ä¸æ­¢ä¸€ä¸ªåœ°æ–¹å¯¼å…¥ memory
```

```python
template = """You are a chatbot having a conversation with a human.

Given the following extracted parts of a long document and a question, create a final answer.

{context}

{chat_history}
Human: {human_input}
Chatbot:"""

prompt = PromptTemplate(
    input_variables=["chat_history", "human_input", "context"],
    template=template
)
memory = ConversationBufferMemory(memory_key="chat_history", input_key="human_input")
chain = load_qa_chain(OpenAI(temperature=0), chain_type="stuff", memory=memory, prompt=prompt)

```

ç„¶åå°±å¯ä»¥ä¸åœçš„é—®äº†

```python
query = "What did the president say about Justice Breyer"
chain({"input_documents": docs, "human_input": query}, return_only_outputs=True)
print(chain.memory.buffer)
```

æ³¨æ„è¿™ä¸ªæ—¶å€™,å¯ä»¥ä¸æ–­çš„é‡å¤ query å’Œ chain çš„æ­¥éª¤,è¿™ä¸ªæ—¶å€™ä¼šåŒæ—¶æ›´æ–° doc å’Œ memory.

ä½†æ˜¯è¿™æ ·ä¹ŸåŒæ—¶å­˜åœ¨ 3 ä¸ªé—®é¢˜

- [x] memory è¶…å‡ºæ€ä¹ˆåŠ (è¿‡é•¿)? âœ… 2023-11-14
- [ ] doc è¿‡é•¿æ€ä¹ˆåŠ?
- [ ] è¶…å‡º 4096 æ€ä¹ˆåŠ?

##### agent_with_memory

##### agent_with_memory_in_db

#### ä¿å­˜ memory history

```python
from langchain.schema import messages_from_dict, messages_to_dict
dicts = messages_to_dict(history.messages)

new_messages = messages_from_dict(dicts)
```

### Chains

#### Add Memory to Chains

å°±æ˜¯çœ‹æ€ä¹ˆæŠŠ message ä¿å­˜

```python

```

##### ConversationChain()

##### load_qa_chain()
